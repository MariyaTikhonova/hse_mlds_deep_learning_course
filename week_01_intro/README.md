# Introduction in DL


## Lectures
* [iad-deep-learning: Intro ](https://www.youtube.com/watch?v=62sP9QKYrgI&list=PLEwK9wdS5g0qa3PIhR6HBDJD_QnrfP8Ei&index=1)
* [iad-deep-learning: Backprop](https://www.youtube.com/watch?v=aSTwlPjJfso&list=PLEwK9wdS5g0qa3PIhR6HBDJD_QnrfP8Ei&index=2)




## Seminar
* seminar [slides](https://github.com/MariyaTikhonova/hse_mlds_deep_learning_course/blob/spring_fall_22/week_01_intro/MLDS%20DL%20Week%201_%20Intro%2012%2004.pdf)
* YSDA backprop notebook [seminar](https://github.com/yandexdataschool/Practical_DL/blob/fall21/week01_backprop/backprop.ipynb)
* Bonus: YSDA sgd notebook [seminar](https://github.com/yandexdataschool/Practical_DL/blob/fall21/week01_backprop/adapdive_sgd/adaptive_sgd.ipynb)


## Other

http://playground.tensorflow.org/ - simple nn visualizer

http://neuralnetworksanddeeplearning.com/chap4.html - Universal approximation theorem 1D example

http://cs231n.github.io/optimization-2/ - cs231 backprop

https://explained.ai/matrix-calculus/ matrix-calculus in dl

https://ruder.io/optimizing-gradient-descent/index.html - Overview of gradient descent optimization algorithms

https://johnchenresearch.github.io/demon/ - Overview of gradient descent optimization algorithms

https://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization - About initialization

