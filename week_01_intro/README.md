# Introduction in DL


## Lectures
* [Intro](https://www.youtube.com/watch?v=62sP9QKYrgI&list=PLEwK9wdS5g0qa3PIhR6HBDJD_QnrfP8Ei&index=1)
* [Backprop](https://www.youtube.com/watch?v=aSTwlPjJfso&list=PLEwK9wdS5g0qa3PIhR6HBDJD_QnrfP8Ei&index=2)


## Seminars
* seminar [slides](https://docs.google.com/presentation/d/1OKDtMxazo7nHRR8CuRkECL6hYXoonILZwymcWbU9btM/edit?usp=sharing)
* YSDA backprop notebook [seminar](https://github.com/yandexdataschool/Practical_DL/blob/fall21/week01_backprop/backprop.ipynb)
* YSDA sgd notebook [seminar](https://github.com/yandexdataschool/Practical_DL/blob/fall21/week01_backprop/adapdive_sgd/adaptive_sgd.ipynb)

## Other

http://playground.tensorflow.org/ - simple nn visualizer

http://neuralnetworksanddeeplearning.com/chap4.html - Universal approximation theorem 1D example

http://cs231n.github.io/optimization-2/ - cs231 backprop

https://explained.ai/matrix-calculus/ matrix-calculus in dl

https://ruder.io/optimizing-gradient-descent/index.html - Overview of gradient descent optimization algorithms

https://johnchenresearch.github.io/demon/ - Overview of gradient descent optimization algorithms

https://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization - About initialization

